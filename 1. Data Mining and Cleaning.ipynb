{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data mining and cleaning Airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using Plots\n",
    "using DataFrames\n",
    "using Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 starting files:\n",
    "* 2019_july_listings.csv\n",
    "* 2019_october_listings.csv\n",
    "* 2020_july_listings.csv\n",
    "* 2020_octuber_listings.csv\n",
    "\n",
    "Which have been altered and tidied in excel from the original files from [here](http://insideairbnb.com/get-the-data.html)\n",
    "\n",
    "Inidividual analysis will be done to each one in case there are particular problems in any one of them. The result of this analysis is to produce 4 clean datasets that have the necessary information to work on the problem\n",
    "\n",
    "The files contain listing data from the previous month. The stated month is the month when they were uploaded. For example,  2019_july_listings.csv contains data from June."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing value treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### October 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.read(\"./data/initial data/2020_october_listings.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at variables and see if they have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = names(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tid\t\t\tInt64\n",
      "2\tname\t\t\tUnion{Missing, String}\n",
      "3\thost_id\t\t\tInt64\n",
      "4\thost_name\t\t\tUnion{Missing, String}\n",
      "5\tneighbourhood_group\t\t\tString\n",
      "6\tneighbourhood\t\t\tString\n",
      "7\tlatitude\t\t\tFloat64\n",
      "8\tlongitude\t\t\tFloat64\n",
      "9\troom_type\t\t\tString\n",
      "10\tprice\t\t\tInt64\n",
      "11\tminimum_nights\t\t\tInt64\n",
      "12\tnumber_of_reviews\t\t\tInt64\n",
      "13\tlast_review\t\t\tUnion{Missing, Date}\n",
      "14\treviews_per_month\t\t\tUnion{Missing, Float64}\n",
      "15\tcalculated_host_listings_count\t\t\tInt64\n",
      "16\tavailability_365\t\t\tInt64\n"
     ]
    }
   ],
   "source": [
    "for i in 1:length(feature_names)\n",
    "    println(string(i), \"\\t\", string(feature_names[i]), \"\\t\\t\\t\", string(eltype(df[!, i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values in some categories. We will see how much they affect and how many they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of rows in full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rows_full = size(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "percentage (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function percentage(fraction, total)\n",
    "    return fraction/total\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will see for each of the columns the percentage of missing values that there are in them. The goal of this is to see of it makes sense to substitute missing values for any dummy variable or if we can eliminate the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "id --> 0.0% missing values\n",
      "\n",
      "name --> 0.034% missing values\n",
      "\n",
      "host_id --> 0.0% missing values\n",
      "\n",
      "host_name --> 0.038% missing values\n",
      "\n",
      "neighbourhood_group --> 0.0% missing values\n",
      "\n",
      "neighbourhood --> 0.0% missing values\n",
      "\n",
      "latitude --> 0.0% missing values\n",
      "\n",
      "longitude --> 0.0% missing values\n",
      "\n",
      "room_type --> 0.0% missing values\n",
      "\n",
      "price --> 0.0% missing values\n",
      "\n",
      "minimum_nights --> 0.0% missing values\n",
      "\n",
      "number_of_reviews --> 0.0% missing values\n",
      "\n",
      "last_review --> 23.546% missing values\n",
      "\n",
      "reviews_per_month --> 23.546% missing values\n",
      "\n",
      "calculated_host_listings_count --> 0.0% missing values\n",
      "\n",
      "availability_365 --> 0.0% missing values"
     ]
    }
   ],
   "source": [
    "for feature in feature_names\n",
    "    index_missing_data = ismissing.(df[:, feature]) # For each column we obtain 1 if missing, 0 if not\n",
    "    \n",
    "    number_missing_data = sum(index_missing_data)\n",
    "    \n",
    "    # Percentage is calculated\n",
    "    per = percentage(number_missing_data, n_rows_full)\n",
    "    \n",
    "    print(\"\\n\\n\", feature, \" --> \", round(per*100, digits = 3) ,\"% missing values\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show which columns to investigate more:\n",
    "* last_review\n",
    "* reviews_per_month\n",
    "\n",
    "For the rest of the columns, missing values can be eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44666, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`last_review` is a date column, `reviews_per_month` is a float that indicates average number of reviews per month. `Missing`values will be substituted by dummy date \"01/01/1900\" and value 0 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Union{Missing, Date},1}:\n",
       " 2019-11-04\n",
       " 2020-09-20\n",
       " 2019-12-02\n",
       " 2014-01-02\n",
       " 2020-03-15\n",
       " 2017-07-21\n",
       " 2019-08-10\n",
       " 2020-09-09\n",
       " 2019-12-09\n",
       " 2020-03-16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1:10, :last_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1900-01-01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_date = Date(Dates.Month(1),Dates.Year(1900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:, :last_review] = coalesce.(df[:, :last_review], dummy_date);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:, :reviews_per_month] =  coalesce.(df[:, :reviews_per_month], 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the missing values are `host_name`and `name`they will be elimnated as they representa a very small percentage of the total observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_host_name = .!ismissing.(df[:, :host_name]); # 1 to rows with non missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44666, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_host_name = df[index_host_name, :];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44649, 16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df_clean_host_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it will be checked if there are still rows with missing `name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = .!ismissing.(df_clean_host_name[:, :name]); # 1 to rows with non missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44634"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this number is less than the number of rows of `df_clean_host_name` cleaning is still needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean_host_name[index_name, :];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44634, 16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final check to see all variables are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " any_missing = colwise(x -> any(ismissing.(x)), df_clean);\n",
    "sum(any_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No values are missing from any of the columns. Clean dataframe is stored in new variable to prevent overwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "october_2020_dataframe = df_clean;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### July 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same process explained with October 2020 is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.read(\"./data/initial data/2020_july_listings.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at variables and see if they have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = names(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tid\t\t\tInt64\n",
      "2\tname\t\t\tUnion{Missing, String}\n",
      "3\thost_id\t\t\tInt64\n",
      "4\thost_name\t\t\tUnion{Missing, String}\n",
      "5\tneighbourhood_group\t\t\tString\n",
      "6\tneighbourhood\t\t\tString\n",
      "7\tlatitude\t\t\tFloat64\n",
      "8\tlongitude\t\t\tFloat64\n",
      "9\troom_type\t\t\tString\n",
      "10\tprice\t\t\tInt64\n",
      "11\tminimum_nights\t\t\tInt64\n",
      "12\tnumber_of_reviews\t\t\tInt64\n",
      "13\tlast_review\t\t\tUnion{Missing, Date}\n",
      "14\treviews_per_month\t\t\tUnion{Missing, Float64}\n",
      "15\tcalculated_host_listings_count\t\t\tInt64\n",
      "16\tavailability_365\t\t\tInt64\n"
     ]
    }
   ],
   "source": [
    "for i in 1:length(feature_names)\n",
    "    println(string(i), \"\\t\", string(feature_names[i]), \"\\t\\t\\t\", string(eltype(df[!, i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values in some categories. We will see how much they affect and how many they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of rows in full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48588"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rows_full = size(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "percentage (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function percentage(fraction, total)\n",
    "    return fraction/total\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will see for each of the columns the percentage of missing values that there are in them. The goal of this is to see of it makes sense to substitute missing values for any dummy variable or if we can eliminate the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "id --> 0.0% missing values\n",
      "\n",
      "name --> 0.033% missing values\n",
      "\n",
      "host_id --> 0.0% missing values\n",
      "\n",
      "host_name --> 0.025% missing values\n",
      "\n",
      "neighbourhood_group --> 0.0% missing values\n",
      "\n",
      "neighbourhood --> 0.0% missing values\n",
      "\n",
      "latitude --> 0.0% missing values\n",
      "\n",
      "longitude --> 0.0% missing values\n",
      "\n",
      "room_type --> 0.0% missing values\n",
      "\n",
      "price --> 0.0% missing values\n",
      "\n",
      "minimum_nights --> 0.0% missing values\n",
      "\n",
      "number_of_reviews --> 0.0% missing values\n",
      "\n",
      "last_review --> 23.376% missing values\n",
      "\n",
      "reviews_per_month --> 23.376% missing values\n",
      "\n",
      "calculated_host_listings_count --> 0.0% missing values\n",
      "\n",
      "availability_365 --> 0.0% missing values"
     ]
    }
   ],
   "source": [
    "for feature in feature_names\n",
    "    index_missing_data = ismissing.(df[:, feature]) # For each column we obtain 1 if missing, 0 if not\n",
    "    \n",
    "    number_missing_data = sum(index_missing_data)\n",
    "    \n",
    "    # Percentage is calculated\n",
    "    per = percentage(number_missing_data, n_rows_full)\n",
    "    \n",
    "    print(\"\\n\\n\", feature, \" --> \", round(per*100, digits = 3) ,\"% missing values\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are similar to before. We need to investigate same columns:\n",
    "* last_review\n",
    "* reviews_per_month\n",
    "\n",
    "For the rest of the columns, missing values can be eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48588, 16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`last_review` is a date column, `reviews_per_month` is a float that indicates average number of reviews per month. `Missing`values will be substituted by dummy date \"01/01/1900\" and value 0 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Union{Missing, Date},1}:\n",
       " 2008-09-22\n",
       " 2019-11-04\n",
       " 2020-06-21\n",
       " 2016-12-23\n",
       " 2019-10-13\n",
       " 2019-12-02\n",
       " 2014-01-02\n",
       " 2020-03-15\n",
       " 2017-07-21\n",
       " 2019-07-29"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1:10, :last_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1900-01-01"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_date = Date(Dates.Month(1),Dates.Year(1900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:, :last_review] = coalesce.(df[:, :last_review], dummy_date);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:, :reviews_per_month] =  coalesce.(df[:, :reviews_per_month], 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the missing values are `host_name`and `name`they will be elimnated as they representa a very small percentage of the total observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_host_name = .!ismissing.(df[:, :host_name]); # 1 to rows with non missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48588, 16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_host_name = df[index_host_name, :];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48576, 16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df_clean_host_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it will be checked if there are still rows with missing `name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = .!ismissing.(df_clean_host_name[:, :name]); # 1 to rows with non missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48560"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this number is less than the number of rows of `df_clean_host_name` cleaning is still needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean_host_name[index_name, :];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48560, 16)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final check to see all variables are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " any_missing = colwise(x -> any(ismissing.(x)), df_clean);\n",
    "sum(any_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No values are missing from any of the columns. Clean dataframe is stored in new variable to prevent overwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_2020_dataframe = df_clean;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### October 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same process explained with October 2020 is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.read(\"./data/initial data/2019_october_listings.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at variables and see if they have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = names(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tid\t\t\tInt64\n",
      "2\tname\t\t\tUnion{Missing, String}\n",
      "3\thost_id\t\t\tInt64\n",
      "4\thost_name\t\t\tUnion{Missing, String}\n",
      "5\tneighbourhood_group\t\t\tString\n",
      "6\tneighbourhood\t\t\tString\n",
      "7\tlatitude\t\t\tFloat64\n",
      "8\tlongitude\t\t\tFloat64\n",
      "9\troom_type\t\t\tString\n",
      "10\tprice\t\t\tInt64\n",
      "11\tminimum_nights\t\t\tInt64\n",
      "12\tnumber_of_reviews\t\t\tInt64\n",
      "13\tlast_review\t\t\tUnion{Missing, Date}\n",
      "14\treviews_per_month\t\t\tUnion{Missing, Float64}\n",
      "15\tcalculated_host_listings_count\t\t\tInt64\n",
      "16\tavailability_365\t\t\tInt64\n"
     ]
    }
   ],
   "source": [
    "for i in 1:length(feature_names)\n",
    "    println(string(i), \"\\t\", string(feature_names[i]), \"\\t\\t\\t\", string(eltype(df[!, i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values in some categories. We will see how much they affect and how many they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of rows in full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48602"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rows_full = size(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "percentage (generic function with 1 method)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function percentage(fraction, total)\n",
    "    return fraction/total\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will see for each of the columns the percentage of missing values that there are in them. The goal of this is to see of it makes sense to substitute missing values for any dummy variable or if we can eliminate the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "id --> 0.0% missing values\n",
      "\n",
      "name --> 0.035% missing values\n",
      "\n",
      "host_id --> 0.0% missing values\n",
      "\n",
      "host_name --> 0.066% missing values\n",
      "\n",
      "neighbourhood_group --> 0.0% missing values\n",
      "\n",
      "neighbourhood --> 0.0% missing values\n",
      "\n",
      "latitude --> 0.0% missing values\n",
      "\n",
      "longitude --> 0.0% missing values\n",
      "\n",
      "room_type --> 0.0% missing values\n",
      "\n",
      "price --> 0.0% missing values\n",
      "\n",
      "minimum_nights --> 0.0% missing values\n",
      "\n",
      "number_of_reviews --> 0.0% missing values\n",
      "\n",
      "last_review --> 19.133% missing values\n",
      "\n",
      "reviews_per_month --> 19.133% missing values\n",
      "\n",
      "calculated_host_listings_count --> 0.0% missing values\n",
      "\n",
      "availability_365 --> 0.0% missing values"
     ]
    }
   ],
   "source": [
    "for feature in feature_names\n",
    "    index_missing_data = ismissing.(df[:, feature]) # For each column we obtain 1 if missing, 0 if not\n",
    "    \n",
    "    number_missing_data = sum(index_missing_data)\n",
    "    \n",
    "    # Percentage is calculated\n",
    "    per = percentage(number_missing_data, n_rows_full)\n",
    "    \n",
    "    print(\"\\n\\n\", feature, \" --> \", round(per*100, digits = 3) ,\"% missing values\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are similar to before. We need to investigate same columns:\n",
    "* last_review\n",
    "* reviews_per_month\n",
    "\n",
    "For the rest of the columns, missing values can be eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48602, 16)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`last_review` is a date column, `reviews_per_month` is a float that indicates average number of reviews per month. `Missing`values will be substituted by dummy date \"01/01/1900\" and value 0 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Union{Missing, Date},1}:\n",
       " 2019-09-24\n",
       " 2018-11-19\n",
       " 2019-09-25\n",
       " 2017-10-05\n",
       " 2019-09-28\n",
       " 2017-07-21\n",
       " 2019-07-29\n",
       " 2019-08-03\n",
       " 2019-10-13\n",
       " 2019-09-16"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1:10, :last_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1900-01-01"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_date = Date(Dates.Month(1),Dates.Year(1900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:, :last_review] = coalesce.(df[:, :last_review], dummy_date);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:, :reviews_per_month] =  coalesce.(df[:, :reviews_per_month], 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the missing values are `host_name`and `name`they will be elimnated as they representa a very small percentage of the total observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_host_name = .!ismissing.(df[:, :host_name]); # 1 to rows with non missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48602, 16)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_host_name = df[index_host_name, :];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48570, 16)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df_clean_host_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it will be checked if there are still rows with missing `name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = .!ismissing.(df_clean_host_name[:, :name]); # 1 to rows with non missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48553"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this number is less than the number of rows of `df_clean_host_name` cleaning is still needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean_host_name[index_name, :];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48553, 16)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final check to see all variables are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " any_missing = colwise(x -> any(ismissing.(x)), df_clean);\n",
    "sum(any_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No values are missing from any of the columns. Clean dataframe is stored in new variable to prevent overwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "october_2019_dataframe = df_clean;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### July 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same process explained with October 2020 is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.read(\"./data/initial data/2019_july_listings.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at variables and see if they have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = names(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tid\t\t\tInt64\n",
      "2\tname\t\t\tUnion{Missing, String}\n",
      "3\thost_id\t\t\tInt64\n",
      "4\thost_name\t\t\tUnion{Missing, String}\n",
      "5\tneighbourhood_group\t\t\tString\n",
      "6\tneighbourhood\t\t\tString\n",
      "7\tlatitude\t\t\tFloat64\n",
      "8\tlongitude\t\t\tFloat64\n",
      "9\troom_type\t\t\tString\n",
      "10\tprice\t\t\tInt64\n",
      "11\tminimum_nights\t\t\tInt64\n",
      "12\tnumber_of_reviews\t\t\tInt64\n",
      "13\tlast_review\t\t\tUnion{Missing, Date}\n",
      "14\treviews_per_month\t\t\tUnion{Missing, Float64}\n",
      "15\tcalculated_host_listings_count\t\t\tInt64\n",
      "16\tavailability_365\t\t\tInt64\n"
     ]
    }
   ],
   "source": [
    "for i in 1:length(feature_names)\n",
    "    println(string(i), \"\\t\", string(feature_names[i]), \"\\t\\t\\t\", string(eltype(df[!, i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values in some categories. We will see how much they affect and how many they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of rows in full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48895"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rows_full = size(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "percentage (generic function with 1 method)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function percentage(fraction, total)\n",
    "    return fraction/total\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will see for each of the columns the percentage of missing values that there are in them. The goal of this is to see of it makes sense to substitute missing values for any dummy variable or if we can eliminate the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "id --> 0.0% missing values\n",
      "\n",
      "name --> 0.033% missing values\n",
      "\n",
      "host_id --> 0.0% missing values\n",
      "\n",
      "host_name --> 0.043% missing values\n",
      "\n",
      "neighbourhood_group --> 0.0% missing values\n",
      "\n",
      "neighbourhood --> 0.0% missing values\n",
      "\n",
      "latitude --> 0.0% missing values\n",
      "\n",
      "longitude --> 0.0% missing values\n",
      "\n",
      "room_type --> 0.0% missing values\n",
      "\n",
      "price --> 0.0% missing values\n",
      "\n",
      "minimum_nights --> 0.0% missing values\n",
      "\n",
      "number_of_reviews --> 0.0% missing values\n",
      "\n",
      "last_review --> 20.558% missing values\n",
      "\n",
      "reviews_per_month --> 20.558% missing values\n",
      "\n",
      "calculated_host_listings_count --> 0.0% missing values\n",
      "\n",
      "availability_365 --> 0.0% missing values"
     ]
    }
   ],
   "source": [
    "for feature in feature_names\n",
    "    index_missing_data = ismissing.(df[:, feature]) # For each column we obtain 1 if missing, 0 if not\n",
    "    \n",
    "    number_missing_data = sum(index_missing_data)\n",
    "    \n",
    "    # Percentage is calculated\n",
    "    per = percentage(number_missing_data, n_rows_full)\n",
    "    \n",
    "    print(\"\\n\\n\", feature, \" --> \", round(per*100, digits = 3) ,\"% missing values\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are similar to before. We need to investigate same columns:\n",
    "* last_review\n",
    "* reviews_per_month\n",
    "\n",
    "For the rest of the columns, missing values can be eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48895, 16)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`last_review` is a date column, `reviews_per_month` is a float that indicates average number of reviews per month. `Missing`values will be substituted by dummy date \"01/01/1900\" and value 0 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Union{Missing, Date},1}:\n",
       " 2018-10-19\n",
       " 2019-05-21\n",
       " missing\n",
       " 2019-07-05\n",
       " 2018-11-19\n",
       " 2019-06-22\n",
       " 2017-10-05\n",
       " 2019-06-24\n",
       " 2017-07-21\n",
       " 2019-06-09"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1:10, :last_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1900-01-01"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_date = Date(Dates.Month(1),Dates.Year(1900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:, :last_review] = coalesce.(df[:, :last_review], dummy_date);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:, :reviews_per_month] =  coalesce.(df[:, :reviews_per_month], 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the missing values are `host_name`and `name`they will be elimnated as they representa a very small percentage of the total observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_host_name = .!ismissing.(df[:, :host_name]); # 1 to rows with non missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48895, 16)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_host_name = df[index_host_name, :];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48874, 16)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df_clean_host_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it will be checked if there are still rows with missing `name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = .!ismissing.(df_clean_host_name[:, :name]); # 1 to rows with non missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48858"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this number is less than the number of rows of `df_clean_host_name` cleaning is still needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean_host_name[index_name, :];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48858, 16)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final check to see all variables are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " any_missing = colwise(x -> any(ismissing.(x)), df_clean);\n",
    "sum(any_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No values are missing from any of the columns. Clean dataframe is stored in new variable to prevent overwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_2019_dataframe = df_clean;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Variable encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is clean, several columns will be encoded in order to do easier analysis:\n",
    "* `neighbourhood_group`\n",
    "* `neighbourhood`\n",
    "* `room_type`\n",
    "\n",
    "Maybe `last_review` could be considered to be encoded [Recently, last 3 months, never]. This is something to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [october_2020_dataframe, july_2020_dataframe, october_2019_dataframe, july_2019_dataframe];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_names = [\"october_2020_dataframe\", \"july_2020_dataframe\", \"october_2019_dataframe\", \"july_2019_dataframe\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_encode = [\"neighbourhood_group\", \"neighbourhood\", \"room_type\" ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " october_2020_dataframe\n",
      " =======================\n",
      " neighbourhood_group\n",
      "5\n",
      " neighbourhood\n",
      "221\n",
      " room_type\n",
      "4\n",
      "\n",
      " july_2020_dataframe\n",
      " =======================\n",
      " neighbourhood_group\n",
      "5\n",
      " neighbourhood\n",
      "222\n",
      " room_type\n",
      "4\n",
      "\n",
      " october_2019_dataframe\n",
      " =======================\n",
      " neighbourhood_group\n",
      "5\n",
      " neighbourhood\n",
      "223\n",
      " room_type\n",
      "4\n",
      "\n",
      " july_2019_dataframe\n",
      " =======================\n",
      " neighbourhood_group\n",
      "5\n",
      " neighbourhood\n",
      "221\n",
      " room_type\n",
      "3"
     ]
    }
   ],
   "source": [
    "for i in 1:length(dataframe_names)\n",
    "    print(\"\\n\\n \", dataframe_names[i])\n",
    "    print(\"\\n =======================\")\n",
    "    \n",
    "    for variable in variables_to_encode\n",
    "        print(\"\\n \", variable, \"\\n\")\n",
    "        unique_values = unique(dataframes[i][:,variable] )\n",
    "        print(length(unique_values))\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `neighbourhood_group`: Can encode directly in all of them\n",
    "* `neighbourhood`: Need to see the 2 (at least) different values\n",
    "* `room_type`: july 2019 only has 3 types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps are to encode the three studied variables in all four datasets using the same coding pattern so the results are better understood in all. This will be accomplished with the following steps:\n",
    "1. Create new column in all datasets indicating what period of time the row corresponds to (oct 2020, jul 2020...)\n",
    "2. Join all datasets in the same one\n",
    "3. Encode the necessary variables globally to ensure encoding is consistent across all datasets\n",
    "4. Separate the data to remake initial datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create new column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`period_code` will be a variable indicating where the data is from. The purpose of this variable is to be able to separate the dataset afterwards.\n",
    "* Oct 2020: `period_code`= 1\n",
    "* Jul 2020: `period_code`= 2 \n",
    "* Oct 2019: `period_code`= 3 \n",
    "* Jul 2019: `period_code`= 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "october_2020_dataframe[:, :period_code] = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_2020_dataframe[:, :period_code] = 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "october_2019_dataframe[:, :period_code] = 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_2019_dataframe[:, :period_code] = 4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Join all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_time_periods = vcat(october_2020_dataframe, july_2020_dataframe, october_2019_dataframe, july_2019_dataframe);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dimensions are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df_all_time_periods,1) == size(october_2020_dataframe,1) + size(july_2020_dataframe,1) + size(october_2019_dataframe,1) + size(july_2019_dataframe, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190605, 17)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(df_all_time_periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Encode all variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `onehot` function used in Homework3 will be used to encode the neccessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onehot (generic function with 2 methods)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function onehot(column, cats=unique(column))\n",
    "    result = zeros(size(column,1) , size(cats,1))\n",
    "    \n",
    "    for i in 1:length(column)\n",
    "        for j in 1:length(cats)\n",
    "            if column[i] == cats[j]\n",
    "                result[i,j] = 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`neigbourhood_group`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×5 Array{Float64,2}:\n",
       " 1.0  0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_neighbourhood_groups = onehot(df_all_time_periods[:, :neighbourhood_group]);\n",
    "onehot_neighbourhood_groups[1:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column headers are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_group_encoded_names = unique(df_all_time_periods[:, :neighbourhood_group]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Manhattan</th><th>Brooklyn</th><th>Queens</th><th>Staten Island</th><th>Bronx</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 5 columns</p><tr><th>1</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& Manhattan & Brooklyn & Queens & Staten Island & Bronx\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t2 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t3 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t4 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t5 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t6 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t7 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t8 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t9 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t10 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×5 DataFrame\n",
       "│ Row │ Manhattan │ Brooklyn │ Queens  │ Staten Island │ Bronx   │\n",
       "│     │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m       │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼───────────┼──────────┼─────────┼───────────────┼─────────┤\n",
       "│ 1   │ 1.0       │ 0.0      │ 0.0     │ 0.0           │ 0.0     │\n",
       "│ 2   │ 0.0       │ 1.0      │ 0.0     │ 0.0           │ 0.0     │\n",
       "│ 3   │ 0.0       │ 1.0      │ 0.0     │ 0.0           │ 0.0     │\n",
       "│ 4   │ 0.0       │ 1.0      │ 0.0     │ 0.0           │ 0.0     │\n",
       "│ 5   │ 1.0       │ 0.0      │ 0.0     │ 0.0           │ 0.0     │\n",
       "│ 6   │ 1.0       │ 0.0      │ 0.0     │ 0.0           │ 0.0     │\n",
       "│ 7   │ 1.0       │ 0.0      │ 0.0     │ 0.0           │ 0.0     │\n",
       "│ 8   │ 0.0       │ 1.0      │ 0.0     │ 0.0           │ 0.0     │\n",
       "│ 9   │ 1.0       │ 0.0      │ 0.0     │ 0.0           │ 0.0     │\n",
       "│ 10  │ 0.0       │ 1.0      │ 0.0     │ 0.0           │ 0.0     │"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehot_neighbourhood_groups = DataFrame(onehot_neighbourhood_groups, neighbourhood_group_encoded_names);\n",
    "df_onehot_neighbourhood_groups[1:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new dataframe is concatenated with the full one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_time_periods_one_hot1 = hcat(df_all_time_periods, df_onehot_neighbourhood_groups);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, a small dataframe will be constructed with the number of instances each of the `neighbourhood_group`occur in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_group_distribution = transpose(sum(onehot_neighbourhood_groups, dims = 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×2 Array{Any,2}:\n",
       " \"Manhattan\"      84194.0\n",
       " \"Brooklyn\"       77274.0\n",
       " \"Queens\"         23144.0\n",
       " \"Staten Island\"   1421.0\n",
       " \"Bronx\"           4572.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbourhood_group_information =  hcat(neighbourhood_group_encoded_names, neighbourhood_group_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>neighbourhood_group</th><th>number_instances</th></tr><tr><th></th><th>Any</th><th>Any</th></tr></thead><tbody><p>5 rows × 2 columns</p><tr><th>1</th><td>Manhattan</td><td>84194.0</td></tr><tr><th>2</th><td>Brooklyn</td><td>77274.0</td></tr><tr><th>3</th><td>Queens</td><td>23144.0</td></tr><tr><th>4</th><td>Staten Island</td><td>1421.0</td></tr><tr><th>5</th><td>Bronx</td><td>4572.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& neighbourhood\\_group & number\\_instances\\\\\n",
       "\t\\hline\n",
       "\t& Any & Any\\\\\n",
       "\t\\hline\n",
       "\t1 & Manhattan & 84194.0 \\\\\n",
       "\t2 & Brooklyn & 77274.0 \\\\\n",
       "\t3 & Queens & 23144.0 \\\\\n",
       "\t4 & Staten Island & 1421.0 \\\\\n",
       "\t5 & Bronx & 4572.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×2 DataFrame\n",
       "│ Row │ neighbourhood_group │ number_instances │\n",
       "│     │ \u001b[90mAny\u001b[39m                 │ \u001b[90mAny\u001b[39m              │\n",
       "├─────┼─────────────────────┼──────────────────┤\n",
       "│ 1   │ Manhattan           │ 84194.0          │\n",
       "│ 2   │ Brooklyn            │ 77274.0          │\n",
       "│ 3   │ Queens              │ 23144.0          │\n",
       "│ 4   │ Staten Island       │ 1421.0           │\n",
       "│ 5   │ Bronx               │ 4572.0           │"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neighbourhood_group_information = DataFrame(neighbourhood_group_information, [:neighbourhood_group, :number_instances])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`neigbourhood`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×223 Array{Float64,2}:\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_neighbourhood = onehot(df_all_time_periods[:, :neighbourhood]);\n",
    "onehot_neighbourhood[1:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column headers are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_encoded_names = unique(df_all_time_periods[:, :neighbourhood]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Midtown</th><th>Clinton Hill</th><th>Bedford-Stuyvesant</th><th>Sunset Park</th><th>Hell's Kitchen</th><th>Upper West Side</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 223 columns (omitted printing of 217 columns)</p><tr><th>1</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>6</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>7</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>10</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& Midtown & Clinton Hill & Bedford-Stuyvesant & Sunset Park & Hell's Kitchen & Upper West Side & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t7 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t10 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×223 DataFrame. Omitted printing of 219 columns\n",
       "│ Row │ Midtown │ Clinton Hill │ Bedford-Stuyvesant │ Sunset Park │\n",
       "│     │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m            │ \u001b[90mFloat64\u001b[39m     │\n",
       "├─────┼─────────┼──────────────┼────────────────────┼─────────────┤\n",
       "│ 1   │ 1.0     │ 0.0          │ 0.0                │ 0.0         │\n",
       "│ 2   │ 0.0     │ 1.0          │ 0.0                │ 0.0         │\n",
       "│ 3   │ 0.0     │ 0.0          │ 1.0                │ 0.0         │\n",
       "│ 4   │ 0.0     │ 0.0          │ 0.0                │ 1.0         │\n",
       "│ 5   │ 0.0     │ 0.0          │ 0.0                │ 0.0         │\n",
       "│ 6   │ 0.0     │ 0.0          │ 0.0                │ 0.0         │\n",
       "│ 7   │ 0.0     │ 0.0          │ 0.0                │ 0.0         │\n",
       "│ 8   │ 0.0     │ 0.0          │ 0.0                │ 0.0         │\n",
       "│ 9   │ 0.0     │ 0.0          │ 0.0                │ 0.0         │\n",
       "│ 10  │ 0.0     │ 0.0          │ 0.0                │ 0.0         │"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehot_neighbourhood = DataFrame(onehot_neighbourhood, neighbourhood_encoded_names);\n",
    "df_onehot_neighbourhood[1:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new dataframe is concatenated with the full one (that has previous one hot already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_time_periods_one_hot2 = hcat(df_all_time_periods_one_hot1, df_onehot_neighbourhood);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, a small dataframe will be constructed with the number of instances each of the `neighbourhood`occur in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_distribution = transpose(sum(onehot_neighbourhood, dims = 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_information =  hcat(neighbourhood_encoded_names, neighbourhood_distribution);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>neighbourhood</th><th>number_instances</th></tr><tr><th></th><th>Any</th><th>Any</th></tr></thead><tbody><p>6 rows × 2 columns</p><tr><th>1</th><td>Midtown</td><td>6261.0</td></tr><tr><th>2</th><td>Clinton Hill</td><td>2211.0</td></tr><tr><th>3</th><td>Bedford-Stuyvesant</td><td>14386.0</td></tr><tr><th>4</th><td>Sunset Park</td><td>1594.0</td></tr><tr><th>5</th><td>Hell's Kitchen</td><td>7627.0</td></tr><tr><th>6</th><td>Upper West Side</td><td>7558.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& neighbourhood & number\\_instances\\\\\n",
       "\t\\hline\n",
       "\t& Any & Any\\\\\n",
       "\t\\hline\n",
       "\t1 & Midtown & 6261.0 \\\\\n",
       "\t2 & Clinton Hill & 2211.0 \\\\\n",
       "\t3 & Bedford-Stuyvesant & 14386.0 \\\\\n",
       "\t4 & Sunset Park & 1594.0 \\\\\n",
       "\t5 & Hell's Kitchen & 7627.0 \\\\\n",
       "\t6 & Upper West Side & 7558.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×2 DataFrame\n",
       "│ Row │ neighbourhood      │ number_instances │\n",
       "│     │ \u001b[90mAny\u001b[39m                │ \u001b[90mAny\u001b[39m              │\n",
       "├─────┼────────────────────┼──────────────────┤\n",
       "│ 1   │ Midtown            │ 6261.0           │\n",
       "│ 2   │ Clinton Hill       │ 2211.0           │\n",
       "│ 3   │ Bedford-Stuyvesant │ 14386.0          │\n",
       "│ 4   │ Sunset Park        │ 1594.0           │\n",
       "│ 5   │ Hell's Kitchen     │ 7627.0           │\n",
       "│ 6   │ Upper West Side    │ 7558.0           │"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neighbourhood_information = DataFrame(neighbourhood_information, [:neighbourhood, :number_instances]);\n",
    "head(df_neighbourhood_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`room_type`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×4 Array{Float64,2}:\n",
       " 1.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_room_type = onehot(df_all_time_periods[:, :room_type]);\n",
    "onehot_room_type[1:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column headers are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_type_encoded_names = unique(df_all_time_periods[:, :room_type]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Entire home/apt</th><th>Private room</th><th>Shared room</th><th>Hotel room</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 4 columns</p><tr><th>1</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& Entire home/apt & Private room & Shared room & Hotel room\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t2 & 1.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t3 & 0.0 & 1.0 & 0.0 & 0.0 \\\\\n",
       "\t4 & 1.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t5 & 0.0 & 1.0 & 0.0 & 0.0 \\\\\n",
       "\t6 & 0.0 & 1.0 & 0.0 & 0.0 \\\\\n",
       "\t7 & 1.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t8 & 0.0 & 1.0 & 0.0 & 0.0 \\\\\n",
       "\t9 & 0.0 & 1.0 & 0.0 & 0.0 \\\\\n",
       "\t10 & 1.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×4 DataFrame\n",
       "│ Row │ Entire home/apt │ Private room │ Shared room │ Hotel room │\n",
       "│     │ \u001b[90mFloat64\u001b[39m         │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m    │\n",
       "├─────┼─────────────────┼──────────────┼─────────────┼────────────┤\n",
       "│ 1   │ 1.0             │ 0.0          │ 0.0         │ 0.0        │\n",
       "│ 2   │ 1.0             │ 0.0          │ 0.0         │ 0.0        │\n",
       "│ 3   │ 0.0             │ 1.0          │ 0.0         │ 0.0        │\n",
       "│ 4   │ 1.0             │ 0.0          │ 0.0         │ 0.0        │\n",
       "│ 5   │ 0.0             │ 1.0          │ 0.0         │ 0.0        │\n",
       "│ 6   │ 0.0             │ 1.0          │ 0.0         │ 0.0        │\n",
       "│ 7   │ 1.0             │ 0.0          │ 0.0         │ 0.0        │\n",
       "│ 8   │ 0.0             │ 1.0          │ 0.0         │ 0.0        │\n",
       "│ 9   │ 0.0             │ 1.0          │ 0.0         │ 0.0        │\n",
       "│ 10  │ 1.0             │ 0.0          │ 0.0         │ 0.0        │"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehot_room_type = DataFrame(onehot_room_type, room_type_encoded_names);\n",
    "df_onehot_room_type[1:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new dataframe is concatenated with the full one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_time_periods_one_hot3 = hcat(df_all_time_periods_one_hot2, df_onehot_room_type);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, a small dataframe will be constructed with the number of instances each of the `neighbourhood_group`occur in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_type_distribution = transpose(sum(onehot_room_type, dims = 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×2 Array{Any,2}:\n",
       " \"Entire home/apt\"  98522.0\n",
       " \"Private room\"     86502.0\n",
       " \"Shared room\"       4339.0\n",
       " \"Hotel room\"        1242.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "room_type_information =  hcat(room_type_encoded_names, room_type_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>neighbourhood_group</th><th>number_instances</th></tr><tr><th></th><th>Any</th><th>Any</th></tr></thead><tbody><p>4 rows × 2 columns</p><tr><th>1</th><td>Entire home/apt</td><td>98522.0</td></tr><tr><th>2</th><td>Private room</td><td>86502.0</td></tr><tr><th>3</th><td>Shared room</td><td>4339.0</td></tr><tr><th>4</th><td>Hotel room</td><td>1242.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& neighbourhood\\_group & number\\_instances\\\\\n",
       "\t\\hline\n",
       "\t& Any & Any\\\\\n",
       "\t\\hline\n",
       "\t1 & Entire home/apt & 98522.0 \\\\\n",
       "\t2 & Private room & 86502.0 \\\\\n",
       "\t3 & Shared room & 4339.0 \\\\\n",
       "\t4 & Hotel room & 1242.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "4×2 DataFrame\n",
       "│ Row │ neighbourhood_group │ number_instances │\n",
       "│     │ \u001b[90mAny\u001b[39m                 │ \u001b[90mAny\u001b[39m              │\n",
       "├─────┼─────────────────────┼──────────────────┤\n",
       "│ 1   │ Entire home/apt     │ 98522.0          │\n",
       "│ 2   │ Private room        │ 86502.0          │\n",
       "│ 3   │ Shared room         │ 4339.0           │\n",
       "│ 4   │ Hotel room          │ 1242.0           │"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_room_type_information = DataFrame(room_type_information, [:neighbourhood_group, :number_instances])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Separate data by initial variable to obtain original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_combined = df_all_time_periods_one_hot3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Oct 2020 `:period_code` = 1\n",
    "* Jul 2020 `:period_code` = 2\n",
    "* Oct 2019 `:period_code` = 3\n",
    "* Jul 2019 `:period_code` = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**October 2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "october_2020_dataframe_encoded = df_final_combined[ df_final_combined[:,:period_code] .== 1, : ];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**July 2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_2020_dataframe_encoded = df_final_combined[ df_final_combined[:,:period_code] .== 2, : ];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**October 2019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "october_2019_dataframe_encoded = df_final_combined[ df_final_combined[:,:period_code] .== 3, : ];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**July 2019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_2019_dataframe_encoded = df_final_combined[ df_final_combined[:,:period_code] .== 4, : ];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if conversions were correctly done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(october_2020_dataframe_encoded, 1) == size(october_2020_dataframe, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(july_2020_dataframe_encoded, 1) == size(july_2020_dataframe, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(october_2019_dataframe_encoded, 1) == size(october_2019_dataframe, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(july_2019_dataframe_encoded, 1) == size(july_2019_dataframe, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cleaning '0' price values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several unreasonable values for the price column. These will be eliminated from the datasets as they will affect in the process of model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum(october_2020_dataframe_encoded[:price])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of zeros is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = october_2020_dataframe_encoded[:price];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count(i->(i== 0), prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows with zeros will be eliminated from all four datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "remove_zeros (generic function with 1 method)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function remove_zeros(df, column)\n",
    "    \n",
    "    # Check initial and expected future size\n",
    "    original_row_number = size(df)[1]\n",
    "    column_values = df[column]\n",
    "    zeros_count = count(i->(i== 0), column_values)\n",
    "    expected_final_row_number = original_row_number - zeros_count\n",
    "    \n",
    "    df_no_zeros = df[df[column] .!= 0, :]\n",
    "    \n",
    "    print(\"Size of final df is as expected:\")\n",
    "    print(size(df_no_zeros)[1] == expected_final_row_number)\n",
    "    \n",
    "    return df_no_zeros\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All dataframes get their zeroes in price removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of final df is as expected:true"
     ]
    }
   ],
   "source": [
    "october_2020_dataframe_encoded = remove_zeros(october_2020_dataframe_encoded, :price);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of final df is as expected:true"
     ]
    }
   ],
   "source": [
    "july_2020_dataframe_encoded = remove_zeros(july_2020_dataframe_encoded, :price);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of final df is as expected:true"
     ]
    }
   ],
   "source": [
    "october_2019_dataframe_encoded = remove_zeros(october_2019_dataframe_encoded, :price);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of final df is as expected:true"
     ]
    }
   ],
   "source": [
    "july_2019_dataframe_encoded = remove_zeros(july_2019_dataframe_encoded, :price);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date will be encoded in an ordinal way. The categories will be:\n",
    "* 5: last review was done within the last month\n",
    "* 4: last review was done within in the last three months\n",
    "* 3: last review was done within the last year\n",
    "* 2: last review was done earler\n",
    "* 1: there are no reviews yet (date is 1900-01-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encode_date (generic function with 1 method)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function encode_date(df)\n",
    "    \n",
    "    # Encoded dates will be stored in last-review_dates_code\n",
    "    last_review_dates = df[:, :last_review];\n",
    "    last_review_dates_code = zeros(length(last_review_dates));\n",
    "    size(last_review_dates) == size(last_review_dates_code)\n",
    "    \n",
    "    # The thresholds for calculating time periods are defined relative to the date of the last review\n",
    "    last_review_date = maximum(df[:, :last_review])\n",
    "    \n",
    "    # Within the last month\n",
    "    threshold_5 = Date(Dates.year(last_review_date), Dates.month(last_review_date)-1, Dates.day(last_review_date));\n",
    "\n",
    "    # Three months earlier\n",
    "    threshold_4 = Date(Dates.year(last_review_date), Dates.month(last_review_date)-3, Dates.day(last_review_date));\n",
    "\n",
    "    # One year earlier\n",
    "    threshold_3 = Date(Dates.year(last_review_date) - 1, Dates.month(last_review_date), Dates.day(last_review_date));\n",
    "\n",
    "    # No review has been introduced\n",
    "    threshold_1 = Date(\"1900-01-01\");\n",
    "\n",
    "    # This will be the \"else\" clause in the if statement\n",
    "    # threshold_2 = otherwise.\n",
    "    \n",
    "    # `last_review_dates_code` is filled out with a loop by comparing dates to established thresholds\n",
    "    \n",
    "    for i in 1:length(last_review_dates)\n",
    "        if last_review_dates[i] >= threshold_5\n",
    "            last_review_dates_code[i] = 5\n",
    "        elseif last_review_dates[i] >= threshold_4\n",
    "            last_review_dates_code[i] = 4\n",
    "        elseif last_review_dates[i] >= threshold_3\n",
    "            last_review_dates_code[i] = 3\n",
    "        elseif last_review_dates[i] == threshold_1\n",
    "            last_review_dates_code[i] = 1\n",
    "        else\n",
    "            last_review_dates_code[i] = 2\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    print(\"\\n\\nDate distribution is :\")\n",
    "    print(countmap(last_review_dates_code))\n",
    "    \n",
    "    # The new encoded date column is included\n",
    "    df[:, :last_review_code] = last_review_dates_code;\n",
    "    \n",
    "    \n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The different months are encoded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Date distribution is :Dict(4.0 => 3493,2.0 => 14318,3.0 => 12509,5.0 => 3804,1.0 => 10485)\n",
      "\n",
      "Date distribution is :Dict(4.0 => 2080,2.0 => 12727,3.0 => 19200,5.0 => 3200,1.0 => 11326)\n",
      "\n",
      "Date distribution is :Dict(4.0 => 5621,2.0 => 10198,3.0 => 5983,5.0 => 17459,1.0 => 9282)\n",
      "\n",
      "Date distribution is :Dict(4.0 => 6297,2.0 => 9677,3.0 => 6876,5.0 => 15961,1.0 => 10036)"
     ]
    }
   ],
   "source": [
    "october_2020_dataframe_encoded = encode_date(october_2020_dataframe_encoded);\n",
    "july_2020_dataframe_encoded = encode_date(july_2020_dataframe_encoded);\n",
    "october_2019_dataframe_encoded = encode_date(october_2019_dataframe_encoded);\n",
    "july_2019_dataframe_encoded = encode_date(july_2019_dataframe_encoded);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save all encoded dataframes as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"./data/treated data/2020_october_listings_encoded.csv\""
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"./data/treated data/2020_october_listings_encoded.csv\", october_2020_dataframe_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"./data/treated data/2020_july_listings_encoded.csv\""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"./data/treated data/2020_july_listings_encoded.csv\", july_2020_dataframe_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"./data/treated data/2019_october_listings_encoded.csv\""
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"./data/treated data/2019_october_listings_encoded.csv\", october_2019_dataframe_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"./data/treated data/2019_july_listings_encoded.csv\""
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"./data/treated data/2019_july_listings_encoded.csv\", july_2019_dataframe_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
